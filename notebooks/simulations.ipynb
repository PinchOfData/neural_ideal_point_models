{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b719b7-f386-4488-bf0d-f129a02da45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = 50000\n",
    "num_ideal_points = 1\n",
    "vocab_size = 100\n",
    "num_covs = 1\n",
    "min_words = 200\n",
    "max_words = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacbcba-8af5-424f-a499-0880df39deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████████▏                                                                                                              | 6372/50000 [01:22<08:59, 80.87it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_documents(\n",
    "    num_docs, \n",
    "    num_ideal_points, \n",
    "    vocab_size, \n",
    "    num_covs,\n",
    "    lambda_, \n",
    "    sigma,\n",
    "    min_words=50, \n",
    "    max_words=100, \n",
    "    random_seed=42\n",
    "):\n",
    "\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    if num_covs > 0:\n",
    "        M_prevalence_covariates = np.zeros((num_docs, num_covs + 1), dtype=int)\n",
    "        M_prevalence_covariates[:, 0] = 1\n",
    "        for i in range(num_covs):\n",
    "            M_prevalence_covariates[:, i + 1] = np.random.randint(2, size=num_docs)     \n",
    "            \n",
    "        mean = np.dot(M_prevalence_covariates, lambda_)\n",
    "        samples = []\n",
    "        for m in mean:\n",
    "            sample = np.random.multivariate_normal(m, sigma)\n",
    "            samples.append(sample)\n",
    "        true_ideal_points = np.array(samples)\n",
    "\n",
    "    else:\n",
    "        M_prevalence_covariates = None\n",
    "        true_ideal_points = np.random.normal(size=(num_docs, num_ideal_points))\n",
    "        \n",
    "    ideal_point_word_matrix = np.random.rand(num_ideal_points, vocab_size)\n",
    "    \n",
    "    documents = []\n",
    "\n",
    "    for i in tqdm(range(num_docs)):\n",
    "        doc_length = np.random.randint(min_words, max_words+1)\n",
    "        doc_ideal_points = true_ideal_points[i]\n",
    "\n",
    "        doc_words = []\n",
    "        for _ in range(doc_length):\n",
    "            word_probs = np.dot(doc_ideal_points, ideal_point_word_matrix)\n",
    "            word_probs = np.exp(word_probs) / np.sum(np.exp(word_probs))  \n",
    "            word_index = np.random.choice(vocab_size, p=word_probs.flatten())\n",
    "            doc_words.append('word_' + str(word_index))\n",
    "\n",
    "        doc_words = ' '.join(doc_words)\n",
    "        documents.append(doc_words)\n",
    "\n",
    "    return true_ideal_points, M_prevalence_covariates, documents\n",
    "\n",
    "if num_covs > 0:\n",
    "    np.random.seed(1)\n",
    "    lambda_ = np.array(\n",
    "        [[0],[1]]\n",
    "    )\n",
    "    sqrt_sigma = np.random.rand(num_ideal_points, num_ideal_points)\n",
    "    sigma = sqrt_sigma * sqrt_sigma.T\n",
    "    \n",
    "    true_ideal_points, M_prevalence_covariates, documents = generate_documents(\n",
    "        num_docs, num_ideal_points, vocab_size, num_covs, lambda_, sigma, min_words, max_words\n",
    "    )\n",
    "else:\n",
    "    true_ideal_points, M_prevalence_covariates, documents = generate_documents(\n",
    "        num_docs, num_ideal_points, vocab_size, num_covs = 0, lambda_ = None, sigma = None, min_words = min_words, max_words = max_words\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6605d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"doc_clean\": documents, \"doc\": documents})\n",
    "if num_covs > 0:\n",
    "    df['cov_0'] = 1\n",
    "    df['cov_1'] = M_prevalence_covariates[:,1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../IdealPointNN/')\n",
    "from corpus import IdealPointCorpus\n",
    "from ideal_point_model import IdealPointNN\n",
    "\n",
    "if num_covs > 0:\n",
    "    train_dataset = IdealPointCorpus(\n",
    "        df,\n",
    "        prevalence = \"~ cov_0 + cov_1 - 1\",\n",
    "    )\n",
    "    m = IdealPointNN(\n",
    "        train_dataset, \n",
    "        n_dims=1,\n",
    "        update_prior=True,\n",
    "        encoder_hidden_layers=[],\n",
    "        decoder_hidden_layers=[],\n",
    "        log_every_n_epochs = 1,\n",
    "        print_every_n_batches = 100\n",
    "    )\n",
    "else:\n",
    "    train_dataset = IdealPointCorpus(\n",
    "        df\n",
    "    )\n",
    "    m = IdealPointNN(\n",
    "        train_dataset, \n",
    "        n_dims=1,\n",
    "        update_prior=False,\n",
    "        encoder_hidden_layers=[],\n",
    "        decoder_hidden_layers=[],\n",
    "        log_every_n_epochs = 1,\n",
    "        print_every_n_batches = 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c112b-8d7a-4cd5-95c7-2e4f7723b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "doc_dims = m.get_doc_dims(train_dataset)\n",
    "\n",
    "x = doc_dims\n",
    "y = true_ideal_points\n",
    "\n",
    "plt.scatter(x, y, label='Data points', s=1)\n",
    "coefficients = np.polyfit(x.flatten(), y.flatten(), 1)\n",
    "fit = np.poly1d(coefficients)\n",
    "plt.plot(x, fit(x), color='red', label='Linear Fit')\n",
    "plt.xlabel('Estimates')\n",
    "plt.ylabel('True Value')\n",
    "plt.title('True vs. Estimated Ideal Points')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edf9d0-145b-48bd-990a-184b38b68eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_covs > 0:\n",
    "    print('True lambda: {}'.format(lambda_))\n",
    "    print('Estimated lambda: {}'.format(m.prior.lambda_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
